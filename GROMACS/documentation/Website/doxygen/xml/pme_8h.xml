<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.8.5">
  <compounddef id="pme_8h" kind="file">
    <compoundname>pme.h</compoundname>
    <includes local="no">string</includes>
    <includes refid="vectypes_8h" local="yes">gromacs/math/vectypes.h</includes>
    <includes refid="wallcycle_8h" local="yes">gromacs/timing/wallcycle.h</includes>
    <includes refid="walltime__accounting_8h" local="yes">gromacs/timing/walltime_accounting.h</includes>
    <includes refid="arrayref_8h" local="yes">gromacs/utility/arrayref.h</includes>
    <includes refid="basedefinitions_8h" local="yes">gromacs/utility/basedefinitions.h</includes>
    <includes refid="real_8h" local="yes">gromacs/utility/real.h</includes>
    <includedby refid="domdec_8cpp" local="yes">src/gromacs/domdec/domdec.cpp</includedby>
    <includedby refid="domdec__setup_8cpp" local="yes">src/gromacs/domdec/domdec_setup.cpp</includedby>
    <includedby refid="pme-gpu-types_8h" local="yes">src/gromacs/ewald/pme-gpu-types.h</includedby>
    <includedby refid="pme-gpu_8cpp" local="yes">src/gromacs/ewald/pme-gpu.cpp</includedby>
    <includedby refid="pme-grid_8cpp" local="yes">src/gromacs/ewald/pme-grid.cpp</includedby>
    <includedby refid="pme-load-balancing_8cpp" local="yes">src/gromacs/ewald/pme-load-balancing.cpp</includedby>
    <includedby refid="pme-only_8cpp" local="yes">src/gromacs/ewald/pme-only.cpp</includedby>
    <includedby refid="pme-pp_8cpp" local="yes">src/gromacs/ewald/pme-pp.cpp</includedby>
    <includedby refid="pme-spread_8cpp" local="yes">src/gromacs/ewald/pme-spread.cpp</includedby>
    <includedby refid="pme_8cpp" local="yes">src/gromacs/ewald/pme.cpp</includedby>
    <includedby refid="pmetestcommon_8h" local="yes">src/gromacs/ewald/tests/pmetestcommon.h</includedby>
    <includedby refid="gmx__pme__error_8cpp" local="yes">src/gromacs/gmxana/gmx_pme_error.cpp</includedby>
    <includedby refid="gmx__tune__pme_8cpp" local="yes">src/gromacs/gmxana/gmx_tune_pme.cpp</includedby>
    <includedby refid="gromacs_2gmxpreprocess_2grompp_8cpp" local="yes">src/gromacs/gmxpreprocess/grompp.cpp</includedby>
    <includedby refid="force_8cpp" local="yes">src/gromacs/mdlib/force.cpp</includedby>
    <includedby refid="mdsetup_8cpp" local="yes">src/gromacs/mdlib/mdsetup.cpp</includedby>
    <includedby refid="minimize_8cpp" local="yes">src/gromacs/mdlib/minimize.cpp</includedby>
    <includedby refid="sim__util_8cpp" local="yes">src/gromacs/mdlib/sim_util.cpp</includedby>
    <includedby refid="tpi_8cpp" local="yes">src/gromacs/mdlib/tpi.cpp</includedby>
    <includedby refid="resourcedivision_8h" local="yes">src/gromacs/taskassignment/resourcedivision.h</includedby>
    <includedby refid="resourcedivision_8cpp" local="yes">src/gromacs/taskassignment/resourcedivision.cpp</includedby>
    <includedby refid="md_8cpp" local="yes">src/programs/mdrun/md.cpp</includedby>
    <includedby refid="runner_8cpp" local="yes">src/programs/mdrun/runner.cpp</includedby>
    <incdepgraph>
      <node id="5601">
        <label>gromacs/utility/current_function.h</label>
        <link refid="current__function_8h"/>
      </node>
      <node id="5593">
        <label>iterator</label>
      </node>
      <node id="5599">
        <label>stdint.h</label>
      </node>
      <node id="5588">
        <label>src/gromacs/ewald/pme.h</label>
        <link refid="pme.h"/>
        <childnode refid="5589" relation="include">
        </childnode>
        <childnode refid="5590" relation="include">
        </childnode>
        <childnode refid="5598" relation="include">
        </childnode>
        <childnode refid="5602" relation="include">
        </childnode>
      </node>
      <node id="5594">
        <label>stdexcept</label>
      </node>
      <node id="5589">
        <label>string</label>
      </node>
      <node id="5597">
        <label>gromacs/utility/gmxassert.h</label>
        <link refid="gmxassert_8h"/>
        <childnode refid="5598" relation="include">
        </childnode>
        <childnode refid="5601" relation="include">
        </childnode>
      </node>
      <node id="5602">
        <label>gromacs/utility/real.h</label>
        <link refid="real_8h"/>
      </node>
      <node id="5596">
        <label>vector</label>
      </node>
      <node id="5595">
        <label>utility</label>
      </node>
      <node id="5592">
        <label>array</label>
      </node>
      <node id="5598">
        <label>gromacs/utility/basedefinitions.h</label>
        <link refid="basedefinitions_8h"/>
        <childnode refid="5599" relation="include">
        </childnode>
        <childnode refid="5600" relation="include">
        </childnode>
      </node>
      <node id="5590">
        <label>gromacs/utility/arrayref.h</label>
        <link refid="arrayref_8h"/>
        <childnode refid="5591" relation="include">
        </childnode>
        <childnode refid="5592" relation="include">
        </childnode>
        <childnode refid="5593" relation="include">
        </childnode>
        <childnode refid="5594" relation="include">
        </childnode>
        <childnode refid="5595" relation="include">
        </childnode>
        <childnode refid="5596" relation="include">
        </childnode>
        <childnode refid="5597" relation="include">
        </childnode>
      </node>
      <node id="5591">
        <label>cstddef</label>
      </node>
      <node id="5600">
        <label>inttypes.h</label>
      </node>
    </incdepgraph>
    <invincdepgraph>
      <node id="5610">
        <label>src/gromacs/ewald/pme-pp.cpp</label>
        <link refid="pme-pp_8cpp"/>
      </node>
      <node id="5604">
        <label>src/gromacs/domdec/domdec_setup.cpp</label>
        <link refid="domdec__setup_8cpp"/>
      </node>
      <node id="5617">
        <label>src/gromacs/ewald/tests/pmesolvetest.cpp</label>
        <link refid="pmesolvetest_8cpp"/>
      </node>
      <node id="5613">
        <label>src/gromacs/ewald/tests/pmetestcommon.cpp</label>
        <link refid="pmetestcommon_8cpp"/>
      </node>
      <node id="5607">
        <label>src/gromacs/ewald/pme-gpu-internal.cpp</label>
        <link refid="pme-gpu-internal_8cpp"/>
      </node>
      <node id="5611">
        <label>src/gromacs/ewald/pme.cpp</label>
        <link refid="pme_8cpp"/>
      </node>
      <node id="5603">
        <label>src/gromacs/ewald/pme.h</label>
        <link refid="pme.h"/>
        <childnode refid="5604" relation="include">
        </childnode>
        <childnode refid="5605" relation="include">
        </childnode>
        <childnode refid="5608" relation="include">
        </childnode>
        <childnode refid="5609" relation="include">
        </childnode>
        <childnode refid="5610" relation="include">
        </childnode>
        <childnode refid="5611" relation="include">
        </childnode>
        <childnode refid="5615" relation="include">
        </childnode>
        <childnode refid="5619" relation="include">
        </childnode>
        <childnode refid="5620" relation="include">
        </childnode>
        <childnode refid="5621" relation="include">
        </childnode>
        <childnode refid="5622" relation="include">
        </childnode>
        <childnode refid="5623" relation="include">
        </childnode>
      </node>
      <node id="5606">
        <label>src/gromacs/ewald/pme-internal.h</label>
        <link refid="pme-internal_8h"/>
        <childnode refid="5607" relation="include">
        </childnode>
        <childnode refid="5608" relation="include">
        </childnode>
        <childnode refid="5609" relation="include">
        </childnode>
        <childnode refid="5610" relation="include">
        </childnode>
        <childnode refid="5611" relation="include">
        </childnode>
        <childnode refid="5612" relation="include">
        </childnode>
        <childnode refid="5613" relation="include">
        </childnode>
      </node>
      <node id="5619">
        <label>src/gromacs/mdlib/minimize.cpp</label>
        <link refid="minimize_8cpp"/>
      </node>
      <node id="5612">
        <label>src/gromacs/ewald/tests/pmebsplinetest.cpp</label>
        <link refid="pmebsplinetest_8cpp"/>
      </node>
      <node id="5609">
        <label>src/gromacs/ewald/pme-load-balancing.cpp</label>
        <link refid="pme-load-balancing_8cpp"/>
      </node>
      <node id="5618">
        <label>src/gromacs/ewald/tests/pmesplinespreadtest.cpp</label>
        <link refid="pmesplinespreadtest_8cpp"/>
      </node>
      <node id="5622">
        <label>src/gromacs/taskassignment/resourcedivision.cpp</label>
        <link refid="resourcedivision_8cpp"/>
      </node>
      <node id="5614">
        <label>src/gromacs/ewald/pme-gpu-internal.h</label>
        <link refid="pme-gpu-internal_8h"/>
        <childnode refid="5607" relation="include">
        </childnode>
        <childnode refid="5608" relation="include">
        </childnode>
        <childnode refid="5611" relation="include">
        </childnode>
        <childnode refid="5615" relation="include">
        </childnode>
        <childnode refid="5613" relation="include">
        </childnode>
      </node>
      <node id="5608">
        <label>src/gromacs/ewald/pme-gpu.cpp</label>
        <link refid="pme-gpu_8cpp"/>
      </node>
      <node id="5616">
        <label>src/gromacs/ewald/tests/pmegathertest.cpp</label>
        <link refid="pmegathertest_8cpp"/>
      </node>
      <node id="5623">
        <label>src/programs/mdrun/runner.cpp</label>
        <link refid="runner_8cpp"/>
      </node>
      <node id="5605">
        <label>src/gromacs/ewald/pme-gpu-types.h</label>
        <link refid="pme-gpu-types_8h"/>
        <childnode refid="5606" relation="include">
        </childnode>
        <childnode refid="5614" relation="include">
        </childnode>
      </node>
      <node id="5621">
        <label>src/gromacs/taskassignment/resourcedivision.h</label>
        <link refid="resourcedivision_8h"/>
        <childnode refid="5622" relation="include">
        </childnode>
        <childnode refid="5623" relation="include">
        </childnode>
      </node>
      <node id="5620">
        <label>src/gromacs/mdlib/tpi.cpp</label>
        <link refid="tpi_8cpp"/>
      </node>
      <node id="5615">
        <label>src/gromacs/ewald/tests/pmetestcommon.h</label>
        <link refid="pmetestcommon_8h"/>
        <childnode refid="5612" relation="include">
        </childnode>
        <childnode refid="5616" relation="include">
        </childnode>
        <childnode refid="5617" relation="include">
        </childnode>
        <childnode refid="5618" relation="include">
        </childnode>
        <childnode refid="5613" relation="include">
        </childnode>
      </node>
    </invincdepgraph>
    <innernamespace refid="namespacegmx">gmx</innernamespace>
      <sectiondef kind="user-defined">
      <memberdef kind="define" id="pme_8h_1ab6d75b83531d15842aaa37feab7d83e2" prot="public" static="no">
        <name>GMX_PME_SPREAD</name>
        <initializer>(1&lt;&lt;0)</initializer>
        <briefdescription>
<para>Flag values that control what <ref refid="pme_8cpp_1a4f11dc953f2403aea6e1e1e49a0a3ac3" kindref="member">gmx_pme_do()</ref> will calculate. </para>        </briefdescription>
        <detaileddescription>
<para>These can be combined with bitwise-OR if more than one thing is required. </para>        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" line="145" column="9" bodyfile="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" bodystart="145" bodyend="-1"/>
      </memberdef>
      <memberdef kind="define" id="pme_8h_1ac6d1376d9a280f7910a157d75e8eba43" prot="public" static="no">
        <name>GMX_PME_SOLVE</name>
        <initializer>(1&lt;&lt;1)</initializer>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" line="146" column="9" bodyfile="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" bodystart="146" bodyend="-1"/>
      </memberdef>
      <memberdef kind="define" id="pme_8h_1ae563d0a2d83859bdbb9fc13746594662" prot="public" static="no">
        <name>GMX_PME_CALC_F</name>
        <initializer>(1&lt;&lt;2)</initializer>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" line="147" column="9" bodyfile="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" bodystart="147" bodyend="-1"/>
      </memberdef>
      <memberdef kind="define" id="pme_8h_1ac367c183d9abb53f9d5c45e46070e72e" prot="public" static="no">
        <name>GMX_PME_CALC_ENER_VIR</name>
        <initializer>(1&lt;&lt;3)</initializer>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" line="148" column="9" bodyfile="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" bodystart="148" bodyend="-1"/>
      </memberdef>
      <memberdef kind="define" id="pme_8h_1a53dd47b2f8893cb1209a1f0c7af9c493" prot="public" static="no">
        <name>GMX_PME_CALC_POT</name>
        <initializer>(1&lt;&lt;4)</initializer>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" line="150" column="9" bodyfile="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" bodystart="150" bodyend="-1"/>
      </memberdef>
      <memberdef kind="define" id="pme_8h_1a5f3f5bfad0e83132220cbeebc499b5e2" prot="public" static="no">
        <name>GMX_PME_DO_ALL_F</name>
        <initializer>(<ref refid="pme_8h_1ab6d75b83531d15842aaa37feab7d83e2" kindref="member">GMX_PME_SPREAD</ref> | GMX_PME_SOLVE | GMX_PME_CALC_F)</initializer>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" line="152" column="9" bodyfile="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" bodystart="152" bodyend="-1"/>
      </memberdef>
      </sectiondef>
      <sectiondef kind="enum">
      <memberdef kind="enum" id="pme_8h_1abc5c98fcc1211af2b80116dd6e0a035d" prot="public" static="no">
        <name>@11</name>
        <enumvalue id="pme_8h_1abc5c98fcc1211af2b80116dd6e0a035da6fde025357df3abb2792aaf0486b3c2c" prot="public">
          <name>GMX_SUM_GRID_FORWARD</name>
          <briefdescription>
          </briefdescription>
          <detaileddescription>
          </detaileddescription>
        </enumvalue>
        <enumvalue id="pme_8h_1abc5c98fcc1211af2b80116dd6e0a035da62abab4ed59db8196ddda5ff8230faae" prot="public">
          <name>GMX_SUM_GRID_BACKWARD</name>
          <briefdescription>
          </briefdescription>
          <detaileddescription>
          </detaileddescription>
        </enumvalue>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" line="77" column="1" bodyfile="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" bodystart="77" bodyend="79"/>
      </memberdef>
      <memberdef kind="enum" id="pme_8h_1adc082ed1af9a4868af13352373ed3791" prot="public" static="no">
        <name>PmeRunMode</name>
        <enumvalue id="pme_8h_1adc082ed1af9a4868af13352373ed3791ac9d3e887722f2bc482bcca9d41c512af" prot="public">
          <name>None</name>
          <briefdescription>
<para>No PME task is done. </para>          </briefdescription>
          <detaileddescription>
          </detaileddescription>
        </enumvalue>
        <enumvalue id="pme_8h_1adc082ed1af9a4868af13352373ed3791a0035eb0600d18dfc302f6bf7a7cbfa3b" prot="public">
          <name>CPU</name>
          <briefdescription>
<para>Whole PME computation is done on CPU. </para>          </briefdescription>
          <detaileddescription>
          </detaileddescription>
        </enumvalue>
        <enumvalue id="pme_8h_1adc082ed1af9a4868af13352373ed3791a90768d506a26e2fd926bc5920b63daad" prot="public">
          <name>GPU</name>
          <briefdescription>
<para>Whole PME computation is done on GPU. </para>          </briefdescription>
          <detaileddescription>
          </detaileddescription>
        </enumvalue>
        <enumvalue id="pme_8h_1adc082ed1af9a4868af13352373ed3791ab92f302712b561470bfc9be49649f99f" prot="public">
          <name>Mixed</name>
          <briefdescription>
<para>Mixed mode: only spread and gather run on GPU; FFT and solving are done on CPU. </para>          </briefdescription>
          <detaileddescription>
          </detaileddescription>
        </enumvalue>
        <briefdescription>
<para>Possible PME codepaths on a rank. </para>        </briefdescription>
        <detaileddescription>
<para><xrefsect id="todo_1_todo000024"><xreftitle>Todo</xreftitle><xrefdescription><para>: make this enum class with gmx_pme_t C++ refactoring </para></xrefdescription></xrefsect></para>        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" line="85" column="1" bodyfile="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" bodystart="84" bodyend="90"/>
      </memberdef>
      <memberdef kind="enum" id="pme_8h_1acbcd1495b351f6a99fa2bf5b10aca640" prot="public" static="no">
        <name>PmeForceOutputHandling</name>
        <enumvalue id="pme_8h_1acbcd1495b351f6a99fa2bf5b10aca640a5d5b78699e57104f2fa03bbdf7b9197b" prot="public">
          <name>Set</name>
          <briefdescription>
<para>Gather simply writes into provided force buffer. </para>          </briefdescription>
          <detaileddescription>
          </detaileddescription>
        </enumvalue>
        <enumvalue id="pme_8h_1acbcd1495b351f6a99fa2bf5b10aca640a42f1eb7ac5a7918712e21bf4e5ca731b" prot="public">
          <name>ReduceWithInput</name>
          <briefdescription>
<para>Gather adds its output to the buffer. </para>          </briefdescription>
          <detaileddescription>
<para>On GPU, that means additional H2D copy before the kernel launch. </para>          </detaileddescription>
        </enumvalue>
        <briefdescription>
<para>PME gathering output forces treatment. </para>        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" line="94" column="1" bodyfile="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" bodystart="93" bodyend="98"/>
      </memberdef>
      </sectiondef>
      <sectiondef kind="func">
      <memberdef kind="function" id="pme_8h_1a3167e04d492823ba4279c5e11417cb8f" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>int</type>
        <definition>int minimalPmeGridSize</definition>
        <argsstring>(int pmeOrder)</argsstring>
        <name>minimalPmeGridSize</name>
        <param>
          <type>int</type>
          <declname>pmeOrder</declname>
        </param>
        <briefdescription>
<para>Return the smallest allowed PME grid size for <computeroutput>pmeOrder</computeroutput>. </para>        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" line="101" column="1" bodyfile="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.cpp" bodystart="435" bodyend="450"/>
      </memberdef>
      <memberdef kind="function" id="pme_8h_1addb389aeee720cd4f4d6bd2f33b31873" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>bool</type>
        <definition>bool gmx_pme_check_restrictions</definition>
        <argsstring>(int pme_order, int nkx, int nky, int nkz, int nnodes_major, bool useThreads, bool errorsAreFatal)</argsstring>
        <name>gmx_pme_check_restrictions</name>
        <param>
          <type>int</type>
          <declname>pme_order</declname>
        </param>
        <param>
          <type>int</type>
          <declname>nkx</declname>
        </param>
        <param>
          <type>int</type>
          <declname>nky</declname>
        </param>
        <param>
          <type>int</type>
          <declname>nkz</declname>
        </param>
        <param>
          <type>int</type>
          <declname>nnodes_major</declname>
        </param>
        <param>
          <type>bool</type>
          <declname>useThreads</declname>
        </param>
        <param>
          <type>bool</type>
          <declname>errorsAreFatal</declname>
        </param>
        <briefdescription>
<para>Check restrictions on pme_order and the PME grid nkx,nky,nkz. </para>        </briefdescription>
        <detaileddescription>
<para>With errorsAreFatal=true, an exception or fatal error is generated on violation of restrictions. With errorsAreFatal=false, false is returned on violation of restrictions. When all restrictions are obeyed, true is returned. Argument useThreads tells if any MPI rank doing PME uses more than 1 threads. If at calling useThreads is unknown, pass true for conservative checking.</para><para>The PME GPU restrictions are checked separately during <ref refid="pme-gpu-internal_8cpp_1adf72d90341055cd222ad34c061236cb9" kindref="member">pme_gpu_init()</ref>. </para>        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" line="114" column="1" bodyfile="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.cpp" bodystart="452" bodyend="501"/>
      </memberdef>
      <memberdef kind="function" id="pme_8h_1aeb51e1b6f53cdf7342fb660a22d65119" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>gmx_pme_t *</type>
        <definition>gmx_pme_t* gmx_pme_init</definition>
        <argsstring>(const t_commrec *cr, int nnodes_major, int nnodes_minor, const t_inputrec *ir, int homenr, gmx_bool bFreeEnergy_q, gmx_bool bFreeEnergy_lj, gmx_bool bReproducible, real ewaldcoeff_q, real ewaldcoeff_lj, int nthread, PmeRunMode runMode, PmeGpu *pmeGpu, gmx_device_info_t *gpuInfo, const gmx::MDLogger &amp;mdlog)</argsstring>
        <name>gmx_pme_init</name>
        <param>
          <type>const <ref refid="structt__commrec" kindref="compound">t_commrec</ref> *</type>
          <declname>cr</declname>
        </param>
        <param>
          <type>int</type>
          <declname>nnodes_major</declname>
        </param>
        <param>
          <type>int</type>
          <declname>nnodes_minor</declname>
        </param>
        <param>
          <type>const <ref refid="structt__inputrec" kindref="compound">t_inputrec</ref> *</type>
          <declname>ir</declname>
        </param>
        <param>
          <type>int</type>
          <declname>homenr</declname>
        </param>
        <param>
          <type><ref refid="basedefinitions_8h_1a8fddad319f226e856400d190198d5151" kindref="member">gmx_bool</ref></type>
          <declname>bFreeEnergy_q</declname>
        </param>
        <param>
          <type><ref refid="basedefinitions_8h_1a8fddad319f226e856400d190198d5151" kindref="member">gmx_bool</ref></type>
          <declname>bFreeEnergy_lj</declname>
        </param>
        <param>
          <type><ref refid="basedefinitions_8h_1a8fddad319f226e856400d190198d5151" kindref="member">gmx_bool</ref></type>
          <declname>bReproducible</declname>
        </param>
        <param>
          <type><ref refid="real_8h_1a58a0c7cf2501f4492da833421be92547" kindref="member">real</ref></type>
          <declname>ewaldcoeff_q</declname>
        </param>
        <param>
          <type><ref refid="real_8h_1a58a0c7cf2501f4492da833421be92547" kindref="member">real</ref></type>
          <declname>ewaldcoeff_lj</declname>
        </param>
        <param>
          <type>int</type>
          <declname>nthread</declname>
        </param>
        <param>
          <type><ref refid="pme_8h_1adc082ed1af9a4868af13352373ed3791" kindref="member">PmeRunMode</ref></type>
          <declname>runMode</declname>
        </param>
        <param>
          <type><ref refid="structPmeGpu" kindref="compound">PmeGpu</ref> *</type>
          <declname>pmeGpu</declname>
        </param>
        <param>
          <type><ref refid="structgmx__device__info__t" kindref="compound">gmx_device_info_t</ref> *</type>
          <declname>gpuInfo</declname>
        </param>
        <param>
          <type>const <ref refid="classgmx_1_1MDLogger" kindref="compound">gmx::MDLogger</ref> &amp;</type>
          <declname>mdlog</declname>
        </param>
        <briefdescription>
<para>Construct PME data. </para>        </briefdescription>
        <detaileddescription>
<para><parameterlist kind="exception"><parameteritem>
<parameternamelist>
<parametername><ref refid="classgmx_1_1InconsistentInputError" kindref="compound">gmx::InconsistentInputError</ref></parametername>
</parameternamelist>
<parameterdescription>
<para>if input grid sizes/PME order are inconsistent. </para></parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>Pointer to newly allocated and initialized PME data. </para></simplesect>
</para>        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" line="125" column="1" bodyfile="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.cpp" bodystart="509" bodyend="862"/>
      </memberdef>
      <memberdef kind="function" id="pme_8h_1ac5a75a2d477885fcb0260908f6e7b2f2" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void gmx_pme_destroy</definition>
        <argsstring>(gmx_pme_t *pme)</argsstring>
        <name>gmx_pme_destroy</name>
        <param>
          <type>gmx_pme_t *</type>
          <declname>pme</declname>
        </param>
        <briefdescription>
<para>Destroys the PME data structure. </para>        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" line="138" column="1" bodyfile="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.cpp" bodystart="1692" bodyend="1756"/>
      </memberdef>
      <memberdef kind="function" id="pme_8h_1a4f11dc953f2403aea6e1e1e49a0a3ac3" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>int</type>
        <definition>int gmx_pme_do</definition>
        <argsstring>(struct gmx_pme_t *pme, int start, int homenr, rvec x[], rvec f[], real chargeA[], real chargeB[], real c6A[], real c6B[], real sigmaA[], real sigmaB[], matrix box, t_commrec *cr, int maxshift_x, int maxshift_y, t_nrnb *nrnb, gmx_wallcycle_t wcycle, matrix vir_q, matrix vir_lj, real *energy_q, real *energy_lj, real lambda_q, real lambda_lj, real *dvdlambda_q, real *dvdlambda_lj, int flags)</argsstring>
        <name>gmx_pme_do</name>
        <param>
          <type>struct gmx_pme_t *</type>
          <declname>pme</declname>
        </param>
        <param>
          <type>int</type>
          <declname>start</declname>
        </param>
        <param>
          <type>int</type>
          <declname>homenr</declname>
        </param>
        <param>
          <type>rvec</type>
          <declname>x</declname>
          <array>[]</array>
        </param>
        <param>
          <type>rvec</type>
          <declname>f</declname>
          <array>[]</array>
        </param>
        <param>
          <type><ref refid="real_8h_1a58a0c7cf2501f4492da833421be92547" kindref="member">real</ref></type>
          <declname>chargeA</declname>
          <array>[]</array>
        </param>
        <param>
          <type><ref refid="real_8h_1a58a0c7cf2501f4492da833421be92547" kindref="member">real</ref></type>
          <declname>chargeB</declname>
          <array>[]</array>
        </param>
        <param>
          <type><ref refid="real_8h_1a58a0c7cf2501f4492da833421be92547" kindref="member">real</ref></type>
          <declname>c6A</declname>
          <array>[]</array>
        </param>
        <param>
          <type><ref refid="real_8h_1a58a0c7cf2501f4492da833421be92547" kindref="member">real</ref></type>
          <declname>c6B</declname>
          <array>[]</array>
        </param>
        <param>
          <type><ref refid="real_8h_1a58a0c7cf2501f4492da833421be92547" kindref="member">real</ref></type>
          <declname>sigmaA</declname>
          <array>[]</array>
        </param>
        <param>
          <type><ref refid="real_8h_1a58a0c7cf2501f4492da833421be92547" kindref="member">real</ref></type>
          <declname>sigmaB</declname>
          <array>[]</array>
        </param>
        <param>
          <type>matrix</type>
          <declname>box</declname>
        </param>
        <param>
          <type><ref refid="structt__commrec" kindref="compound">t_commrec</ref> *</type>
          <declname>cr</declname>
        </param>
        <param>
          <type>int</type>
          <declname>maxshift_x</declname>
        </param>
        <param>
          <type>int</type>
          <declname>maxshift_y</declname>
        </param>
        <param>
          <type><ref refid="structt__nrnb" kindref="compound">t_nrnb</ref> *</type>
          <declname>nrnb</declname>
        </param>
        <param>
          <type><ref refid="structgmx__wallcycle" kindref="compound">gmx_wallcycle_t</ref></type>
          <declname>wcycle</declname>
        </param>
        <param>
          <type>matrix</type>
          <declname>vir_q</declname>
        </param>
        <param>
          <type>matrix</type>
          <declname>vir_lj</declname>
        </param>
        <param>
          <type><ref refid="real_8h_1a58a0c7cf2501f4492da833421be92547" kindref="member">real</ref> *</type>
          <declname>energy_q</declname>
        </param>
        <param>
          <type><ref refid="real_8h_1a58a0c7cf2501f4492da833421be92547" kindref="member">real</ref> *</type>
          <declname>energy_lj</declname>
        </param>
        <param>
          <type><ref refid="real_8h_1a58a0c7cf2501f4492da833421be92547" kindref="member">real</ref></type>
          <declname>lambda_q</declname>
        </param>
        <param>
          <type><ref refid="real_8h_1a58a0c7cf2501f4492da833421be92547" kindref="member">real</ref></type>
          <declname>lambda_lj</declname>
        </param>
        <param>
          <type><ref refid="real_8h_1a58a0c7cf2501f4492da833421be92547" kindref="member">real</ref> *</type>
          <declname>dvdlambda_q</declname>
        </param>
        <param>
          <type><ref refid="real_8h_1a58a0c7cf2501f4492da833421be92547" kindref="member">real</ref> *</type>
          <declname>dvdlambda_lj</declname>
        </param>
        <param>
          <type>int</type>
          <declname>flags</declname>
        </param>
        <briefdescription>
<para>Do a PME calculation on a CPU for the long range electrostatics and/or LJ. </para>        </briefdescription>
        <detaileddescription>
<para>The meaning of <computeroutput>flags</computeroutput> is defined above, and determines which parts of the calculation are performed.</para><para><simplesect kind="return"><para>0 indicates all well, non zero is an error code. </para></simplesect>
</para>        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" line="162" column="1" bodyfile="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.cpp" bodystart="981" bodyend="1690"/>
      </memberdef>
      <memberdef kind="function" id="pme_8h_1a516424aeaca910d927b8b1ee74e1758d" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>int</type>
        <definition>int gmx_pmeonly</definition>
        <argsstring>(struct gmx_pme_t *pme, struct t_commrec *cr, t_nrnb *mynrnb, gmx_wallcycle_t wcycle, gmx_walltime_accounting_t walltime_accounting, t_inputrec *ir, PmeRunMode runMode)</argsstring>
        <name>gmx_pmeonly</name>
        <param>
          <type>struct gmx_pme_t *</type>
          <declname>pme</declname>
        </param>
        <param>
          <type>struct <ref refid="structt__commrec" kindref="compound">t_commrec</ref> *</type>
          <declname>cr</declname>
        </param>
        <param>
          <type><ref refid="structt__nrnb" kindref="compound">t_nrnb</ref> *</type>
          <declname>mynrnb</declname>
        </param>
        <param>
          <type><ref refid="structgmx__wallcycle" kindref="compound">gmx_wallcycle_t</ref></type>
          <declname>wcycle</declname>
        </param>
        <param>
          <type><ref refid="structgmx__walltime__accounting" kindref="compound">gmx_walltime_accounting_t</ref></type>
          <declname>walltime_accounting</declname>
        </param>
        <param>
          <type><ref refid="structt__inputrec" kindref="compound">t_inputrec</ref> *</type>
          <declname>ir</declname>
        </param>
        <param>
          <type><ref refid="pme_8h_1adc082ed1af9a4868af13352373ed3791" kindref="member">PmeRunMode</ref></type>
          <declname>runMode</declname>
        </param>
        <briefdescription>
<para>Called on the nodes that do PME exclusively (as slaves) </para>        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" line="178" column="1" bodyfile="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme-only.cpp" bodystart="535" bodyend="674"/>
      </memberdef>
      <memberdef kind="function" id="pme_8h_1a6a1f7f848b8e4e23576a856f80251abd" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void gmx_pme_calc_energy</definition>
        <argsstring>(struct gmx_pme_t *pme, int n, rvec *x, real *q, real *V)</argsstring>
        <name>gmx_pme_calc_energy</name>
        <param>
          <type>struct gmx_pme_t *</type>
          <declname>pme</declname>
        </param>
        <param>
          <type>int</type>
          <declname>n</declname>
        </param>
        <param>
          <type>rvec *</type>
          <declname>x</declname>
        </param>
        <param>
          <type><ref refid="real_8h_1a58a0c7cf2501f4492da833421be92547" kindref="member">real</ref> *</type>
          <declname>q</declname>
        </param>
        <param>
          <type><ref refid="real_8h_1a58a0c7cf2501f4492da833421be92547" kindref="member">real</ref> *</type>
          <declname>V</declname>
        </param>
        <briefdescription>
<para>Calculate the PME grid energy V for n charges. </para>        </briefdescription>
        <detaileddescription>
<para>The potential (found in <computeroutput>pme</computeroutput>) must have been found already with a call to <ref refid="pme_8cpp_1a4f11dc953f2403aea6e1e1e49a0a3ac3" kindref="member">gmx_pme_do()</ref> with at least GMX_PME_SPREAD and GMX_PME_SOLVE specified. Note that the charges are not spread on the grid in the pme struct. Currently does not work in parallel or with free energy. </para>        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" line="192" column="1" bodyfile="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.cpp" bodystart="917" bodyend="952"/>
      </memberdef>
      <memberdef kind="function" id="pme_8h_1a9036aa66d9959c10ab85d96e0966b84e" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void gmx_pme_send_parameters</definition>
        <argsstring>(struct t_commrec *cr, const interaction_const_t *ic, gmx_bool bFreeEnergy_q, gmx_bool bFreeEnergy_lj, real *chargeA, real *chargeB, real *sqrt_c6A, real *sqrt_c6B, real *sigmaA, real *sigmaB, int maxshift_x, int maxshift_y)</argsstring>
        <name>gmx_pme_send_parameters</name>
        <param>
          <type>struct <ref refid="structt__commrec" kindref="compound">t_commrec</ref> *</type>
          <declname>cr</declname>
        </param>
        <param>
          <type>const <ref refid="structinteraction__const__t" kindref="compound">interaction_const_t</ref> *</type>
          <declname>ic</declname>
        </param>
        <param>
          <type><ref refid="basedefinitions_8h_1a8fddad319f226e856400d190198d5151" kindref="member">gmx_bool</ref></type>
          <declname>bFreeEnergy_q</declname>
        </param>
        <param>
          <type><ref refid="basedefinitions_8h_1a8fddad319f226e856400d190198d5151" kindref="member">gmx_bool</ref></type>
          <declname>bFreeEnergy_lj</declname>
        </param>
        <param>
          <type><ref refid="real_8h_1a58a0c7cf2501f4492da833421be92547" kindref="member">real</ref> *</type>
          <declname>chargeA</declname>
        </param>
        <param>
          <type><ref refid="real_8h_1a58a0c7cf2501f4492da833421be92547" kindref="member">real</ref> *</type>
          <declname>chargeB</declname>
        </param>
        <param>
          <type><ref refid="real_8h_1a58a0c7cf2501f4492da833421be92547" kindref="member">real</ref> *</type>
          <declname>sqrt_c6A</declname>
        </param>
        <param>
          <type><ref refid="real_8h_1a58a0c7cf2501f4492da833421be92547" kindref="member">real</ref> *</type>
          <declname>sqrt_c6B</declname>
        </param>
        <param>
          <type><ref refid="real_8h_1a58a0c7cf2501f4492da833421be92547" kindref="member">real</ref> *</type>
          <declname>sigmaA</declname>
        </param>
        <param>
          <type><ref refid="real_8h_1a58a0c7cf2501f4492da833421be92547" kindref="member">real</ref> *</type>
          <declname>sigmaB</declname>
        </param>
        <param>
          <type>int</type>
          <declname>maxshift_x</declname>
        </param>
        <param>
          <type>int</type>
          <declname>maxshift_y</declname>
        </param>
        <briefdescription>
<para>Send the charges and maxshift to out PME-only node. </para>        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" line="195" column="1" bodyfile="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme-pp.cpp" bodystart="215" bodyend="244"/>
      </memberdef>
      <memberdef kind="function" id="pme_8h_1a8e6232a31facc9ae1295456fe2ed852f" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void gmx_pme_send_coordinates</definition>
        <argsstring>(struct t_commrec *cr, matrix box, rvec *x, real lambda_q, real lambda_lj, gmx_bool bEnerVir, gmx_int64_t step)</argsstring>
        <name>gmx_pme_send_coordinates</name>
        <param>
          <type>struct <ref refid="structt__commrec" kindref="compound">t_commrec</ref> *</type>
          <declname>cr</declname>
        </param>
        <param>
          <type>matrix</type>
          <declname>box</declname>
        </param>
        <param>
          <type>rvec *</type>
          <declname>x</declname>
        </param>
        <param>
          <type><ref refid="real_8h_1a58a0c7cf2501f4492da833421be92547" kindref="member">real</ref></type>
          <declname>lambda_q</declname>
        </param>
        <param>
          <type><ref refid="real_8h_1a58a0c7cf2501f4492da833421be92547" kindref="member">real</ref></type>
          <declname>lambda_lj</declname>
        </param>
        <param>
          <type><ref refid="basedefinitions_8h_1a8fddad319f226e856400d190198d5151" kindref="member">gmx_bool</ref></type>
          <declname>bEnerVir</declname>
        </param>
        <param>
          <type>gmx_int64_t</type>
          <declname>step</declname>
        </param>
        <briefdescription>
<para>Send the coordinates to our PME-only node and request a PME calculation. </para>        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" line="204" column="1" bodyfile="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme-pp.cpp" bodystart="246" bodyend="258"/>
      </memberdef>
      <memberdef kind="function" id="pme_8h_1a2f834326084fb098046006e21cf0a186" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void gmx_pme_send_finish</definition>
        <argsstring>(struct t_commrec *cr)</argsstring>
        <name>gmx_pme_send_finish</name>
        <param>
          <type>struct <ref refid="structt__commrec" kindref="compound">t_commrec</ref> *</type>
          <declname>cr</declname>
        </param>
        <briefdescription>
<para>Tell our PME-only node to finish. </para>        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" line="210" column="1" bodyfile="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme-pp.cpp" bodystart="260" bodyend="265"/>
      </memberdef>
      <memberdef kind="function" id="pme_8h_1a4c472206ea895284fd905ef66ec72d57" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void gmx_pme_send_resetcounters</definition>
        <argsstring>(struct t_commrec *cr, gmx_int64_t step)</argsstring>
        <name>gmx_pme_send_resetcounters</name>
        <param>
          <type>struct <ref refid="structt__commrec" kindref="compound">t_commrec</ref> *</type>
          <declname>cr</declname>
        </param>
        <param>
          <type>gmx_int64_t</type>
          <declname>step</declname>
        </param>
        <briefdescription>
<para>Tell our PME-only node to reset all cycle and flop counters. </para>        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" line="213" column="1" bodyfile="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme-pp.cpp" bodystart="290" bodyend="306"/>
      </memberdef>
      <memberdef kind="function" id="pme_8h_1a65c64c95cb32d5a4c8e0f7a61a042eef" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void gmx_pme_receive_f</definition>
        <argsstring>(struct t_commrec *cr, gmx::ForceWithVirial *forceWithVirial, real *energy_q, real *energy_lj, real *dvdlambda_q, real *dvdlambda_lj, float *pme_cycles)</argsstring>
        <name>gmx_pme_receive_f</name>
        <param>
          <type>struct <ref refid="structt__commrec" kindref="compound">t_commrec</ref> *</type>
          <declname>cr</declname>
        </param>
        <param>
          <type><ref refid="classgmx_1_1ForceWithVirial" kindref="compound">gmx::ForceWithVirial</ref> *</type>
          <declname>forceWithVirial</declname>
        </param>
        <param>
          <type><ref refid="real_8h_1a58a0c7cf2501f4492da833421be92547" kindref="member">real</ref> *</type>
          <declname>energy_q</declname>
        </param>
        <param>
          <type><ref refid="real_8h_1a58a0c7cf2501f4492da833421be92547" kindref="member">real</ref> *</type>
          <declname>energy_lj</declname>
        </param>
        <param>
          <type><ref refid="real_8h_1a58a0c7cf2501f4492da833421be92547" kindref="member">real</ref> *</type>
          <declname>dvdlambda_q</declname>
        </param>
        <param>
          <type><ref refid="real_8h_1a58a0c7cf2501f4492da833421be92547" kindref="member">real</ref> *</type>
          <declname>dvdlambda_lj</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>pme_cycles</declname>
        </param>
        <briefdescription>
<para>PP nodes receive the long range forces from the PME nodes. </para>        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" line="216" column="1" bodyfile="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme-pp.cpp" bodystart="353" bodyend="405"/>
      </memberdef>
      <memberdef kind="function" id="pme_8h_1a2bbcd1698af0baadd183fc819b0c96f2" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void gmx_pme_reinit_atoms</definition>
        <argsstring>(const gmx_pme_t *pme, const int nAtoms, const real *charges)</argsstring>
        <name>gmx_pme_reinit_atoms</name>
        <param>
          <type>const gmx_pme_t *</type>
          <declname>pme</declname>
        </param>
        <param>
          <type>const int</type>
          <declname>nAtoms</declname>
        </param>
        <param>
          <type>const <ref refid="real_8h_1a58a0c7cf2501f4492da833421be92547" kindref="member">real</ref> *</type>
          <declname>charges</declname>
        </param>
        <briefdescription>
<para>This function updates the local atom data on GPU after DD (charges, coordinates, etc.). TODO: it should update the PME CPU atom data as well. (currently PME CPU call <ref refid="pme_8cpp_1a4f11dc953f2403aea6e1e1e49a0a3ac3" kindref="member">gmx_pme_do()</ref> gets passed the input pointers for each computation). </para>        </briefdescription>
        <detaileddescription>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername direction="in">pme</parametername>
</parameternamelist>
<parameterdescription>
<para>The PME structure. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername direction="in">nAtoms</parametername>
</parameternamelist>
<parameterdescription>
<para>The number of particles. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername direction="in">charges</parametername>
</parameternamelist>
<parameterdescription>
<para>The pointer to the array of particle charges. </para></parameterdescription>
</parameteritem>
</parameterlist>
</para>        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" line="231" column="1" bodyfile="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.cpp" bodystart="1758" bodyend="1765"/>
      </memberdef>
      <memberdef kind="function" id="pme_8h_1a877779523026740bee18ecc68ca9ab42" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>bool</type>
        <definition>bool pme_gpu_supports_input</definition>
        <argsstring>(const t_inputrec *ir, std::string *error)</argsstring>
        <name>pme_gpu_supports_input</name>
        <param>
          <type>const <ref refid="structt__inputrec" kindref="compound">t_inputrec</ref> *</type>
          <declname>ir</declname>
        </param>
        <param>
          <type>std::string *</type>
          <declname>error</declname>
        </param>
        <briefdescription>
<para>Checks whether the input system allows to run PME on GPU. TODO: this mostly duplicates an internal PME assert function <ref refid="pme-gpu-internal_8cpp_1a30f29ab01f4617cea28a55ee8552ee6a" kindref="member">pme_gpu_check_restrictions()</ref>, except that works with a formed gmx_pme_t structure. Should that one go away/work with inputrec? </para>        </briefdescription>
        <detaileddescription>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername direction="in">ir</parametername>
</parameternamelist>
<parameterdescription>
<para>Input system. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername direction="out">error</parametername>
</parameternamelist>
<parameterdescription>
<para>The error message if the input is not supported on GPU.</para></parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>true if PME can run on GPU with this input, false otherwise. </para></simplesect>
</para>        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" line="245" column="1" bodyfile="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme-gpu.cpp" bodystart="70" bodyend="116"/>
      </memberdef>
      <memberdef kind="function" id="pme_8h_1a9cfbe9fa691aabaf1a9e10fa06858c96" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type><ref refid="pme_8h_1adc082ed1af9a4868af13352373ed3791" kindref="member">PmeRunMode</ref></type>
        <definition>PmeRunMode pme_run_mode</definition>
        <argsstring>(const gmx_pme_t *pme)</argsstring>
        <name>pme_run_mode</name>
        <param>
          <type>const gmx_pme_t *</type>
          <declname>pme</declname>
        </param>
        <briefdescription>
<para>Returns the active PME codepath (CPU, GPU, mixed). </para>        </briefdescription>
        <detaileddescription>
<para><xrefsect id="todo_1_todo000025"><xreftitle>Todo</xreftitle><xrefdescription><para>This is a rather static data that should be managed by the higher level task scheduler.</para></xrefdescription></xrefsect></para><para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername direction="in">pme</parametername>
</parameternamelist>
<parameterdescription>
<para>The PME data structure. </para></parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>active PME codepath. </para></simplesect>
</para>        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" line="254" column="1" bodyfile="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme-gpu.cpp" bodystart="64" bodyend="68"/>
      </memberdef>
      <memberdef kind="function" id="pme_8h_1a9faddde52f5a636410141f52cc95d3e1" prot="public" static="no" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>bool</type>
        <definition>bool pme_gpu_task_enabled</definition>
        <argsstring>(const gmx_pme_t *pme)</argsstring>
        <name>pme_gpu_task_enabled</name>
        <param>
          <type>const gmx_pme_t *</type>
          <declname>pme</declname>
        </param>
        <briefdescription>
<para>Tells if PME is enabled to run on GPU (not necessarily active at the moment). </para>        </briefdescription>
        <detaileddescription>
<para><xrefsect id="todo_1_todo000026"><xreftitle>Todo</xreftitle><xrefdescription><para>This is a rather static data that should be managed by the hardware assignment manager. For now, it is synonymous with the active PME codepath (in the absence of dynamic switching).</para></xrefdescription></xrefsect></para><para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername direction="in">pme</parametername>
</parameternamelist>
<parameterdescription>
<para>The PME data structure. </para></parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>true if PME can run on GPU, false otherwise. </para></simplesect>
</para>        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" line="264" column="1" bodyfile="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" bodystart="264" bodyend="267"/>
      </memberdef>
      <memberdef kind="function" id="pme_8h_1a9e82dc29271032072ff9ffb1418a1954" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void pme_gpu_reset_timings</definition>
        <argsstring>(const gmx_pme_t *pme)</argsstring>
        <name>pme_gpu_reset_timings</name>
        <param>
          <type>const gmx_pme_t *</type>
          <declname>pme</declname>
        </param>
        <briefdescription>
<para>Resets the PME GPU timings. To be called at the reset step. </para>        </briefdescription>
        <detaileddescription>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername direction="in">pme</parametername>
</parameternamelist>
<parameterdescription>
<para>The PME structure. </para></parameterdescription>
</parameteritem>
</parameterlist>
</para>        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" line="274" column="1" bodyfile="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme-gpu.cpp" bodystart="118" bodyend="124"/>
      </memberdef>
      <memberdef kind="function" id="pme_8h_1aadcdbd368ce25a9899c3cab4ec895cba" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void pme_gpu_get_timings</definition>
        <argsstring>(const gmx_pme_t *pme, gmx_wallclock_gpu_pme_t *timings)</argsstring>
        <name>pme_gpu_get_timings</name>
        <param>
          <type>const gmx_pme_t *</type>
          <declname>pme</declname>
        </param>
        <param>
          <type><ref refid="structgmx__wallclock__gpu__pme__t" kindref="compound">gmx_wallclock_gpu_pme_t</ref> *</type>
          <declname>timings</declname>
        </param>
        <briefdescription>
<para>Copies the PME GPU timings to the <ref refid="structgmx__wallclock__gpu__pme__t" kindref="compound">gmx_wallclock_gpu_pme_t</ref> structure (for log output). To be called at the run end. </para>        </briefdescription>
        <detaileddescription>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername direction="in">pme</parametername>
</parameternamelist>
<parameterdescription>
<para>The PME structure. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername direction="in">timings</parametername>
</parameternamelist>
<parameterdescription>
<para>The <ref refid="structgmx__wallclock__gpu__pme__t" kindref="compound">gmx_wallclock_gpu_pme_t</ref> structure. </para></parameterdescription>
</parameteritem>
</parameterlist>
</para>        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" line="282" column="1" bodyfile="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme-gpu.cpp" bodystart="126" bodyend="132"/>
      </memberdef>
      <memberdef kind="function" id="pme_8h_1a2db9507955e1908ed647984a9c62f641" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void pme_gpu_prepare_computation</definition>
        <argsstring>(gmx_pme_t *pme, bool needToUpdateBox, const matrix box, gmx_wallcycle_t wcycle, int flags)</argsstring>
        <name>pme_gpu_prepare_computation</name>
        <param>
          <type>gmx_pme_t *</type>
          <declname>pme</declname>
        </param>
        <param>
          <type>bool</type>
          <declname>needToUpdateBox</declname>
        </param>
        <param>
          <type>const matrix</type>
          <declname>box</declname>
        </param>
        <param>
          <type><ref refid="structgmx__wallcycle" kindref="compound">gmx_wallcycle_t</ref></type>
          <declname>wcycle</declname>
        </param>
        <param>
          <type>int</type>
          <declname>flags</declname>
        </param>
        <briefdescription>
<para>Prepares PME on GPU computation (updating the box if needed) </para>        </briefdescription>
        <detaileddescription>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername direction="in">pme</parametername>
</parameternamelist>
<parameterdescription>
<para>The PME data structure. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername direction="in">needToUpdateBox</parametername>
</parameternamelist>
<parameterdescription>
<para>Tells if the stored unit cell parameters should be updated from <computeroutput>box</computeroutput>. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername direction="in">box</parametername>
</parameternamelist>
<parameterdescription>
<para>The unit cell box. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername direction="in">wcycle</parametername>
</parameternamelist>
<parameterdescription>
<para>The wallclock counter. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername direction="in">flags</parametername>
</parameternamelist>
<parameterdescription>
<para>The combination of flags to affect this PME computation. The flags are the GMX_PME_ flags from <ref refid="pme_8h" kindref="compound">pme.h</ref>. </para></parameterdescription>
</parameteritem>
</parameterlist>
</para>        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" line="296" column="1" bodyfile="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme-gpu.cpp" bodystart="170" bodyend="211"/>
      </memberdef>
      <memberdef kind="function" id="pme_8h_1afa0375d05b42903aa5fa89ecca162848" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void pme_gpu_launch_spread</definition>
        <argsstring>(gmx_pme_t *pme, const rvec *x, gmx_wallcycle_t wcycle)</argsstring>
        <name>pme_gpu_launch_spread</name>
        <param>
          <type>gmx_pme_t *</type>
          <declname>pme</declname>
        </param>
        <param>
          <type>const rvec *</type>
          <declname>x</declname>
        </param>
        <param>
          <type><ref refid="structgmx__wallcycle" kindref="compound">gmx_wallcycle_t</ref></type>
          <declname>wcycle</declname>
        </param>
        <briefdescription>
<para>Launches first stage of PME on GPU - H2D input transfers, spreading kernel, and D2H grid transfer if needed. </para>        </briefdescription>
        <detaileddescription>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername direction="in">pme</parametername>
</parameternamelist>
<parameterdescription>
<para>The PME data structure. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername direction="in">x</parametername>
</parameternamelist>
<parameterdescription>
<para>The array of local atoms&apos; coordinates. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername direction="in">wcycle</parametername>
</parameternamelist>
<parameterdescription>
<para>The wallclock counter. </para></parameterdescription>
</parameteritem>
</parameterlist>
</para>        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" line="309" column="1" bodyfile="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme-gpu.cpp" bodystart="214" bodyend="242"/>
      </memberdef>
      <memberdef kind="function" id="pme_8h_1a2efd4cd94bfa8f861b22936d2655b148" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void pme_gpu_launch_complex_transforms</definition>
        <argsstring>(gmx_pme_t *pme, gmx_wallcycle_t wcycle)</argsstring>
        <name>pme_gpu_launch_complex_transforms</name>
        <param>
          <type>gmx_pme_t *</type>
          <declname>pme</declname>
        </param>
        <param>
          <type><ref refid="structgmx__wallcycle" kindref="compound">gmx_wallcycle_t</ref></type>
          <declname>wcycle</declname>
        </param>
        <briefdescription>
<para>Launches middle stages of PME (FFT R2C, solving, FFT C2R) either on GPU or on CPU, depending on the run mode. </para>        </briefdescription>
        <detaileddescription>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername direction="in">pme</parametername>
</parameternamelist>
<parameterdescription>
<para>The PME data structure. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername direction="in">wcycle</parametername>
</parameternamelist>
<parameterdescription>
<para>The wallclock counter. </para></parameterdescription>
</parameteritem>
</parameterlist>
</para>        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" line="319" column="1" bodyfile="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme-gpu.cpp" bodystart="244" bodyend="298"/>
      </memberdef>
      <memberdef kind="function" id="pme_8h_1a48278ccbf705df4307a2e9cc984a6b3a" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void pme_gpu_launch_gather</definition>
        <argsstring>(const gmx_pme_t *pme, gmx_wallcycle_t wcycle, PmeForceOutputHandling forceTreatment)</argsstring>
        <name>pme_gpu_launch_gather</name>
        <param>
          <type>const gmx_pme_t *</type>
          <declname>pme</declname>
        </param>
        <param>
          <type><ref refid="structgmx__wallcycle" kindref="compound">gmx_wallcycle_t</ref></type>
          <declname>wcycle</declname>
        </param>
        <param>
          <type><ref refid="pme_8h_1acbcd1495b351f6a99fa2bf5b10aca640" kindref="member">PmeForceOutputHandling</ref></type>
          <declname>forceTreatment</declname>
        </param>
        <briefdescription>
<para>Launches last stage of PME on GPU - force gathering and D2H force transfer. </para>        </briefdescription>
        <detaileddescription>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername direction="in">pme</parametername>
</parameternamelist>
<parameterdescription>
<para>The PME data structure. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername direction="in">wcycle</parametername>
</parameternamelist>
<parameterdescription>
<para>The wallclock counter. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername direction="in">forceTreatment</parametername>
</parameternamelist>
<parameterdescription>
<para>Tells how data should be treated. The gathering kernel either stores the output reciprocal forces into the host array, or copies its contents to the GPU first and accumulates. The reduction is non-atomic. </para></parameterdescription>
</parameteritem>
</parameterlist>
</para>        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" line="331" column="1" bodyfile="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme-gpu.cpp" bodystart="300" bodyend="318"/>
      </memberdef>
      <memberdef kind="function" id="pme_8h_1a6675ff9b6502c7f5e4a9b43eb0103da3" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void pme_gpu_wait_finish_task</definition>
        <argsstring>(const gmx_pme_t *pme, gmx_wallcycle_t wcycle, gmx::ArrayRef&lt; const gmx::RVec &gt; *forces, matrix virial, real *energy)</argsstring>
        <name>pme_gpu_wait_finish_task</name>
        <param>
          <type>const gmx_pme_t *</type>
          <declname>pme</declname>
        </param>
        <param>
          <type><ref refid="structgmx__wallcycle" kindref="compound">gmx_wallcycle_t</ref></type>
          <declname>wcycle</declname>
        </param>
        <param>
          <type><ref refid="classgmx_1_1ArrayRef" kindref="compound">gmx::ArrayRef</ref>&lt; const <ref refid="namespacegmx_1a139c1919a9680de4ad1450f42e37d33b" kindref="member">gmx::RVec</ref> &gt; *</type>
          <declname>forces</declname>
        </param>
        <param>
          <type>matrix</type>
          <declname>virial</declname>
        </param>
        <param>
          <type><ref refid="real_8h_1a58a0c7cf2501f4492da833421be92547" kindref="member">real</ref> *</type>
          <declname>energy</declname>
        </param>
        <briefdescription>
<para>Blocks until PME GPU tasks are completed, and gets the output forces and virial/energy (if they were to be computed). </para>        </briefdescription>
        <detaileddescription>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername direction="in">pme</parametername>
</parameternamelist>
<parameterdescription>
<para>The PME data structure. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername direction="out">wcycle</parametername>
</parameternamelist>
<parameterdescription>
<para>The wallclock counter. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername direction="out">forces</parametername>
</parameternamelist>
<parameterdescription>
<para>The output forces. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername direction="out">virial</parametername>
</parameternamelist>
<parameterdescription>
<para>The output virial matrix. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername direction="out">energy</parametername>
</parameternamelist>
<parameterdescription>
<para>The output energy. </para></parameterdescription>
</parameteritem>
</parameterlist>
</para>        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" line="345" column="1" bodyfile="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme-gpu.cpp" bodystart="393" bodyend="400"/>
      </memberdef>
      <memberdef kind="function" id="pme_8h_1a3f34e80606d5e1fbc6f825e3e9d6cffc" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>bool</type>
        <definition>bool pme_gpu_try_finish_task</definition>
        <argsstring>(const gmx_pme_t *pme, gmx_wallcycle_t wcycle, gmx::ArrayRef&lt; const gmx::RVec &gt; *forces, matrix virial, real *energy, GpuTaskCompletion completionKind)</argsstring>
        <name>pme_gpu_try_finish_task</name>
        <param>
          <type>const gmx_pme_t *</type>
          <declname>pme</declname>
        </param>
        <param>
          <type><ref refid="structgmx__wallcycle" kindref="compound">gmx_wallcycle_t</ref></type>
          <declname>wcycle</declname>
        </param>
        <param>
          <type><ref refid="classgmx_1_1ArrayRef" kindref="compound">gmx::ArrayRef</ref>&lt; const <ref refid="namespacegmx_1a139c1919a9680de4ad1450f42e37d33b" kindref="member">gmx::RVec</ref> &gt; *</type>
          <declname>forces</declname>
        </param>
        <param>
          <type>matrix</type>
          <declname>virial</declname>
        </param>
        <param>
          <type><ref refid="real_8h_1a58a0c7cf2501f4492da833421be92547" kindref="member">real</ref> *</type>
          <declname>energy</declname>
        </param>
        <param>
          <type><ref refid="gpu__utils_8h_1aab3d31c4bd3fcb89aa5d554b125b403e" kindref="member">GpuTaskCompletion</ref></type>
          <declname>completionKind</declname>
        </param>
        <briefdescription>
<para>Attempts to complete PME GPU tasks. </para>        </briefdescription>
        <detaileddescription>
<para>The <computeroutput>completionKind</computeroutput> argument controls whether the function blocks until all PME GPU tasks enqueued completed (as <ref refid="pme-gpu_8cpp_1a6675ff9b6502c7f5e4a9b43eb0103da3" kindref="member">pme_gpu_wait_finish_task()</ref> does) or only checks and returns immediately if they did not. When blocking or the tasks have completed it also gets the output forces by assigning the ArrayRef to the <computeroutput>forces</computeroutput> pointer passed in. Virial/energy are also outputs if they were to be computed.</para><para>Note: also launches the reinitalization of the PME output buffers. TODO: this should be moved out to avoid miscounting its wall-time (as wait iso launch).</para><para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername direction="in">pme</parametername>
</parameternamelist>
<parameterdescription>
<para>The PME data structure. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername direction="in">wcycle</parametername>
</parameternamelist>
<parameterdescription>
<para>The wallclock counter. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername direction="out">forces</parametername>
</parameternamelist>
<parameterdescription>
<para>The output forces. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername direction="out">virial</parametername>
</parameternamelist>
<parameterdescription>
<para>The output virial matrix. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername direction="out">energy</parametername>
</parameternamelist>
<parameterdescription>
<para>The output energy. </para></parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername direction="in">completionKind</parametername>
</parameternamelist>
<parameterdescription>
<para>Indicates whether PME task completion should only be checked rather than waited for </para></parameterdescription>
</parameteritem>
</parameterlist>
<simplesect kind="return"><para>True if the PME GPU tasks have completed </para></simplesect>
</para>        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h" line="371" column="1" bodyfile="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme-gpu.cpp" bodystart="348" bodyend="391"/>
      </memberdef>
      </sectiondef>
    <briefdescription>
<para>This file contains function declarations necessary for computing energies and forces for the PME long-ranged part (Coulomb and LJ). </para>    </briefdescription>
    <detaileddescription>
<para> <libinternal /> </para><para><simplesect kind="author"><para>Berk Hess <ulink url="mailto:hess@kth.se">hess@kth.se</ulink> </para></simplesect>
</para>    </detaileddescription>
    <location file="/home/jenkins/workspace/Release_workflow_master/gromacs-2018.3/src/gromacs/ewald/pme.h"/>
  </compounddef>
</doxygen>
